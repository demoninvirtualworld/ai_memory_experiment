"""
è®°å¿†å¼•æ“ (Memory Engine)

åŸºäºè®¤çŸ¥å¿ƒç†å­¦ç†è®ºçš„å››çº§è®°å¿†æ¶æ„å®ç°ï¼š
- L1 æ„Ÿè§‰è®°å¿† (sensory_memory): æ— ç¼–ç ï¼Œè¿”å›ç©º
- L2 å·¥ä½œè®°å¿† (working_memory): Miller 7Â±2ï¼Œä¿ç•™æœ€è¿‘Nè½®
- L3 è¦ä¹‰è®°å¿† (gist_memory): Verbatimâ†’Gistï¼Œè¿‘æœŸåŸè¯+å†å²æ‘˜è¦
- L4 æ··åˆè®°å¿† (hybrid_memory): çŸ­æ—¶ç„¦ç‚¹+å‘é‡æ£€ç´¢ï¼ˆChromaï¼‰

æ‰€æœ‰æ•°æ®æ“ä½œé€šè¿‡ DBManager å®Œæˆ
å‘é‡æ£€ç´¢é€šè¿‡ VectorStore å®Œæˆ
"""

from typing import List, Dict, Optional, Tuple
from datetime import datetime

from database import DBManager, ChatMessage
from database.vector_store import VectorStore, MemoryItem, get_vector_store
from config import Config


class MemoryEngine:
    """
    è®°å¿†å¼•æ“

    è´Ÿè´£æ ¹æ®ç”¨æˆ·çš„è®°å¿†ç»„åˆ«ï¼Œä»æ•°æ®åº“æå–å¹¶æ ¼å¼åŒ–å†å²å¯¹è¯ä¸Šä¸‹æ–‡
    """

    # ä» config.py è¯»å–é…ç½®
    MEMORY_CONFIG = Config.EXPERIMENT_CONFIG.get('memory_config', {})

    # é»˜è®¤é…ç½®ï¼ˆå¦‚æœ config.py ä¸­æ²¡æœ‰ï¼‰
    WORKING_MEMORY_TURNS = MEMORY_CONFIG.get('working_memory', {}).get('turns', 7)
    RECENT_VERBATIM_TURNS = MEMORY_CONFIG.get('gist_memory', {}).get('recent_turns', 3)
    RETRIEVAL_TOP_K = MEMORY_CONFIG.get('hybrid_memory', {}).get('retrieval_top_k', 3)
    GIST_MAX_CHARS = MEMORY_CONFIG.get('gist_memory', {}).get('gist_max_chars', 500)

    def __init__(self, db_manager: DBManager, llm_manager=None, vector_store: VectorStore = None):
        """
        åˆå§‹åŒ–è®°å¿†å¼•æ“

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
            llm_manager: LLMç®¡ç†å™¨ï¼ˆç”¨äºç”Ÿæˆæ‘˜è¦ï¼Œå¯é€‰ï¼‰
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹ï¼ˆç”¨äº L4 æ··åˆè®°å¿†ï¼Œå¯é€‰ï¼‰
        """
        self.db = db_manager
        self.llm_manager = llm_manager
        self._current_query: Optional[str] = None
        # L4 æ··åˆè®°å¿†çš„å‘é‡å­˜å‚¨
        self._vector_store = vector_store

    def set_current_query(self, query: str):
        """è®¾ç½®å½“å‰æŸ¥è¯¢ï¼ˆç”¨äº L4 æ··åˆè®°å¿†çš„ç›¸å…³æ€§æ£€ç´¢ï¼‰"""
        self._current_query = query

    def get_memory_context(
        self,
        user_id: str,
        memory_group: str,
        current_task_id: int
    ) -> str:
        """
        è·å–è®°å¿†ä¸Šä¸‹æ–‡

        æ ¹æ®è®°å¿†ç»„åˆ«è¿”å›æ ¼å¼åŒ–çš„å†å²å¯¹è¯æ–‡æœ¬ï¼Œå¯ç›´æ¥ç”¨äºæ„å»º System Prompt

        Args:
            user_id: ç”¨æˆ·ID
            memory_group: è®°å¿†ç»„åˆ« (sensory_memory, working_memory, gist_memory, hybrid_memory)
            current_task_id: å½“å‰ä»»åŠ¡IDï¼ˆç”¨äºè¿‡æ»¤å†å²ï¼‰

        Returns:
            æ ¼å¼åŒ–çš„è®°å¿†ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        # è·¯ç”±åˆ°å¯¹åº”çš„è®°å¿†å¤„ç†æ–¹æ³•
        handlers = {
            'sensory_memory': self._get_sensory_context,
            'working_memory': self._get_working_context,
            'gist_memory': self._get_gist_context,
            'hybrid_memory': self._get_hybrid_context,
        }

        handler = handlers.get(memory_group)
        if handler:
            return handler(user_id, current_task_id)

        # æœªçŸ¥çš„è®°å¿†ç»„åˆ«ï¼Œè¿”å›ç©º
        return ""

    # ============ L1: æ„Ÿè§‰è®°å¿† ============

    def _get_sensory_context(self, user_id: str, current_task_id: int) -> str:
        """
        L1: æ„Ÿè§‰è®°å¿† (Sensory Memory)

        å¿ƒç†å­¦åŸºç¡€: Atkinson-Shiffrin æ„Ÿè§‰å¯„å­˜å™¨
        - ä¿¡æ¯æœªè¿›å…¥æ„è¯†åŠ å·¥ï¼Œæ— ç¼–ç 
        - å®¹é‡ = 0

        å®ç°: è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        return ""

    # ============ L2: å·¥ä½œè®°å¿† ============

    def _get_working_context(self, user_id: str, current_task_id: int) -> str:
        """
        L2: å·¥ä½œè®°å¿† (Working Memory)

        å¿ƒç†å­¦åŸºç¡€: Miller (1956) 7Â±2 æ³•åˆ™
        - ä»¥ç»„å—(Chunk)ä¸ºå•ä½å­˜å‚¨
        - è¶…å‡ºå®¹é‡æ—¶å‘ç”Ÿä½å—æ›¿æ¢(Displacement)

        å®ç°: ä¿ç•™æœ€è¿‘ N è½®å¯¹è¯ (é»˜è®¤7è½®)
        """
        # è·å–å½“å‰ä»»åŠ¡ä¹‹å‰çš„æ‰€æœ‰æ¶ˆæ¯
        messages = self.db.get_messages_before_task(user_id, current_task_id)

        if not messages:
            return ""

        # è½¬æ¢ä¸ºè½®æ¬¡
        turns = self._messages_to_turns(messages)

        if not turns:
            return ""

        # å–æœ€è¿‘ N è½®
        recent_turns = turns[-self.WORKING_MEMORY_TURNS:]

        # æ ¼å¼åŒ–è¾“å‡º
        return self._format_turns(recent_turns)

    # ============ L3: è¦ä¹‰è®°å¿† ============

    def _get_gist_context(self, user_id: str, current_task_id: int) -> str:
        """
        L3: è¦ä¹‰è®°å¿† (Gist Memory)

        å¿ƒç†å­¦åŸºç¡€: Fuzzy Trace Theory (Brainerd & Reyna)
        - Verbatim Trace: ç²¾ç¡®ä½†è¡°é€€å¿«
        - Gist Trace: è¯­ä¹‰æœ¬è´¨ï¼Œè¡°é€€æ…¢

        å®ç°:
        - æœ€è¿‘ 3 è½®: ä¿ç•™ Verbatim (åŸè¯)
        - æ›´æ—©å†å²: è½¬åŒ–ä¸º Gist (è¦ä¹‰æ‘˜è¦)
        """
        messages = self.db.get_messages_before_task(user_id, current_task_id)

        if not messages:
            return ""

        turns = self._messages_to_turns(messages)

        if not turns:
            return ""

        context_parts = []

        # 1. æ›´æ—©çš„å†å² â†’ è¯»å–å›ºåŒ–çš„ç”¨æˆ·ç”»åƒï¼ˆGistï¼‰
        if len(turns) > self.RECENT_VERBATIM_TURNS:
            # ä¼˜å…ˆè¯»å–å›ºåŒ–çš„ç”»åƒï¼ˆé¿å…å®æ—¶ç”Ÿæˆå»¶è¿Ÿï¼‰
            gist = self._get_consolidated_gist(user_id)

            # å¦‚æœç”»åƒä¸å­˜åœ¨ï¼Œé™çº§ä¸ºå®æ—¶ç”Ÿæˆ
            if not gist:
                older_turns = turns[:-self.RECENT_VERBATIM_TURNS]
                gist = self._generate_gist_summary(older_turns)

            if gist:
                context_parts.append(f"[ç”¨æˆ·ç”»åƒ]\n{gist}")

        # 2. æœ€è¿‘ N è½® â†’ ä¿ç•™åŸè¯ (Verbatim)
        recent_turns = turns[-self.RECENT_VERBATIM_TURNS:]
        if recent_turns:
            verbatim = self._format_turns(recent_turns)
            if verbatim:
                context_parts.append(f"[è¿‘æœŸå¯¹è¯]\n{verbatim}")

        return "\n\n".join(context_parts)

    def _get_consolidated_gist(self, user_id: str) -> str:
        """
        è¯»å–å›ºåŒ–çš„ç”¨æˆ·ç”»åƒï¼ˆL3/L4 é€šç”¨ï¼‰

        åŒ…å«ï¼š
        - åŸºç¡€å­—æ®µï¼šbasic_info, preferences, constraints, goals, personality, social
        - æƒ…æ„Ÿæ˜¾è‘—æ€§å­—æ®µï¼šemotional_needs, core_values, significant_events

        Returns:
            æ ¼å¼åŒ–çš„ç”»åƒæ–‡æœ¬ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            profile = self.db.get_user_profile(user_id)

            if not profile or not any(profile.values()):
                return ""

            # æ ¼å¼åŒ–ç”»åƒä¸ºè‡ªç„¶è¯­è¨€
            lines = []

            # === åŸºç¡€å­—æ®µ ===
            if profile.get('basic_info'):
                info = profile['basic_info']
                if info:
                    lines.append("åŸºæœ¬ä¿¡æ¯ï¼š" + "ï¼Œ".join(f"{k}: {v}" for k, v in info.items()))

            if profile.get('preferences'):
                prefs = profile['preferences']
                if prefs:
                    lines.append("åå¥½ï¼š" + "ã€".join(prefs))

            if profile.get('constraints'):
                constraints = profile['constraints']
                if constraints:
                    lines.append("é™åˆ¶ï¼š" + "ã€".join(constraints))

            if profile.get('goals'):
                goals = profile['goals']
                if goals:
                    lines.append("ç›®æ ‡ï¼š" + "ã€".join(goals))

            if profile.get('personality'):
                personality = profile['personality']
                if personality:
                    lines.append("æ€§æ ¼ï¼š" + "ã€".join(personality))

            if profile.get('social'):
                social = profile['social']
                if social:
                    lines.append("ç¤¾äº¤ï¼š" + "ã€".join(social))

            # === æƒ…æ„Ÿæ˜¾è‘—æ€§å­—æ®µï¼ˆCHI'24 å¢å¼ºï¼‰ ===
            if profile.get('emotional_needs'):
                emotional_needs = profile['emotional_needs']
                if emotional_needs:
                    lines.append("æ·±å±‚æƒ…æ„Ÿéœ€æ±‚ï¼š" + "ã€".join(emotional_needs))

            if profile.get('core_values'):
                core_values = profile['core_values']
                if core_values:
                    lines.append("æ ¸å¿ƒä»·å€¼è§‚ï¼š" + "ã€".join(core_values))

            if profile.get('significant_events'):
                significant_events = profile['significant_events']
                if significant_events:
                    lines.append("é‡è¦äº‹ä»¶ï¼š" + "ã€".join(significant_events))

            return "\n".join(lines) if lines else ""

        except Exception as e:
            print(f"[MemoryEngine] è¯»å–å›ºåŒ–ç”»åƒå¤±è´¥: {e}")
            return ""

    # ============ L4: æ··åˆè®°å¿† ============

    def _get_hybrid_context(self, user_id: str, current_task_id: int) -> str:
        """
        L4: æ··åˆè®°å¿† (Hybrid Long-term Memory)

        å¿ƒç†å­¦åŸºç¡€: Tulving é™ˆè¿°æ€§è®°å¿† + æ‰©æ•£æ¿€æ´» + Ebbinghaus é—å¿˜æ›²çº¿
        - æ— é™å®¹é‡ä½†å—æå–çº¿ç´¢å½±å“
        - ç¼–ç ç‰¹å¼‚æ€§åŸåˆ™
        - åŠ¨æ€é—å¿˜æ›²çº¿ï¼ˆCHI'24 Hou et al.ï¼‰

        å®ç°ï¼ˆä¸‰éƒ¨åˆ†ï¼‰:
        1. ç”¨æˆ·ç”»åƒ: è¯»å– L3 å›ºåŒ–çš„ç”¨æˆ·ç‰¹å¾ï¼ˆå«æƒ…æ„Ÿæ˜¾è‘—æ€§ï¼‰
        2. çŸ­æ—¶æˆåˆ†: æœ€è¿‘ 3 è½® (å½“å‰ç„¦ç‚¹)
        3. é•¿æ—¶æˆåˆ†: åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢ + æƒ…æ„Ÿæ˜¾è‘—æ€§åŠ æƒ
        """
        messages = self.db.get_messages_before_task(user_id, current_task_id)

        if not messages:
            return ""

        turns = self._messages_to_turns(messages)

        context_parts = []

        # ğŸ”´ 1. ç”¨æˆ·ç”»åƒ: è¯»å– L3 å›ºåŒ–çš„ç”»åƒï¼ˆå«æƒ…æ„Ÿæ˜¾è‘—æ€§å­—æ®µï¼‰
        # L4 æ¯” L3 æ›´å¼ºï¼Œåº”è¯¥ä¹Ÿèƒ½è·å–ç”¨æˆ·ç”»åƒä¿¡æ¯
        user_profile = self._get_consolidated_gist(user_id)
        if user_profile:
            context_parts.append(f"[ç”¨æˆ·ç”»åƒ]\n{user_profile}")

        # 2. çŸ­æ—¶æˆåˆ†: æœ€è¿‘ N è½® (å½“å‰ç„¦ç‚¹)
        if turns:
            recent_turns = turns[-self.RECENT_VERBATIM_TURNS:]
            if recent_turns:
                recent_text = self._format_turns(recent_turns)
                if recent_text:
                    context_parts.append(f"[å½“å‰å¯¹è¯]\n{recent_text}")

        # 3. é•¿æ—¶æˆåˆ†: åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢ï¼ˆèåˆæƒ…æ„Ÿæ˜¾è‘—æ€§ï¼‰
        query = self._current_query
        if query:
            # å°è¯•ä½¿ç”¨å‘é‡å­˜å‚¨è¿›è¡Œæ£€ç´¢
            retrieved_memories = self._get_vector_search_v2(
                user_id=user_id,
                query=query,
                exclude_task_id=current_task_id
            )

            if retrieved_memories:
                retrieved_text = self._format_memory_items(retrieved_memories)
                if retrieved_text:
                    context_parts.append(f"[ç›¸å…³å†å²çº¿ç´¢]\n{retrieved_text}")
            elif turns and len(turns) > self.RECENT_VERBATIM_TURNS:
                # é™çº§æ–¹æ¡ˆï¼šå…³é”®è¯åŒ¹é…
                older_turns = turns[:-self.RECENT_VERBATIM_TURNS]
                fallback = self._keyword_search(older_turns, query)
                if fallback:
                    fallback_text = self._format_turns_with_source(fallback)
                    if fallback_text:
                        context_parts.append(f"[ç›¸å…³å†å²çº¿ç´¢]\n{fallback_text}")

        return "\n\n".join(context_parts)

    def _get_vector_search_v2(
        self,
        user_id: str,
        query: str,
        exclude_task_id: int = None
    ) -> List[MemoryItem]:
        """
        ä½¿ç”¨ VectorStore è¿›è¡Œå‘é‡æ£€ç´¢

        ä¼˜å…ˆä½¿ç”¨åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢ï¼ˆCHI'24 Hou et al.ï¼‰ï¼š
        - å…¬å¼: p_n(t) = [1 - exp(-rÂ·e^{-t/g_n})] / (1-e^{-1})
        - ç‰¹ç‚¹: æ¦‚ç‡é˜ˆå€¼è§¦å‘ï¼Œå¬å›åæ›´æ–°å›ºåŒ–ç³»æ•°

        é™çº§æ–¹æ¡ˆ: é™æ€åŠ æƒæ£€ç´¢
        - å…¬å¼: Score = Î±Â·Recency + Î²Â·Similarity + Î³Â·Importance

        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢æ–‡æœ¬
            exclude_task_id: æ’é™¤çš„ä»»åŠ¡ID

        Returns:
            æ£€ç´¢åˆ°çš„è®°å¿†åˆ—è¡¨
        """
        # è·å–å‘é‡å­˜å‚¨å®ä¾‹ï¼ˆä¼ å…¥ db_managerï¼‰
        vector_store = self._vector_store or get_vector_store(self.db)

        if not vector_store or not vector_store.db:
            return []

        # è¯»å–é—å¿˜æ›²çº¿é…ç½®
        forgetting_curve_config = Config.EXPERIMENT_CONFIG.get('memory_config', {}).get(
            'hybrid_memory', {}
        ).get('forgetting_curve', {})

        use_forgetting_curve = forgetting_curve_config.get('enabled', True)

        try:
            if use_forgetting_curve:
                # ä¼˜å…ˆä½¿ç”¨åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢
                print(f"[MemoryEngine] ä½¿ç”¨åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢")
                results = vector_store.search_with_forgetting_curve(
                    user_id=user_id,
                    query=query,
                    exclude_task_id=exclude_task_id,
                    top_k=self.RETRIEVAL_TOP_K,
                    update_on_recall=forgetting_curve_config.get('update_on_recall', True)
                )

                # å¦‚æœåŠ¨æ€æ£€ç´¢æ²¡æœ‰ç»“æœï¼ˆå¯èƒ½æ˜¯é˜ˆå€¼å¤ªé«˜ï¼‰ï¼Œé™çº§åˆ°é™æ€æ£€ç´¢
                if not results:
                    print(f"[MemoryEngine] åŠ¨æ€æ£€ç´¢æ— ç»“æœï¼Œé™çº§åˆ°é™æ€æ£€ç´¢")
                    results = vector_store.search_weighted(
                        user_id=user_id,
                        query=query,
                        exclude_task_id=exclude_task_id,
                        top_k=self.RETRIEVAL_TOP_K
                    )
            else:
                # ä½¿ç”¨é™æ€åŠ æƒæ£€ç´¢
                results = vector_store.search_weighted(
                    user_id=user_id,
                    query=query,
                    exclude_task_id=exclude_task_id,
                    top_k=self.RETRIEVAL_TOP_K
                )

            return results

        except Exception as e:
            print(f"[MemoryEngine] å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _format_memory_items(self, memories: List[MemoryItem]) -> str:
        """
        æ ¼å¼åŒ–å‘é‡æ£€ç´¢ç»“æœ

        Args:
            memories: MemoryItem åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        if not memories:
            return ""

        lines = []
        for mem in memories:
            task_label = f"ç¬¬{mem.task_id}æ¬¡å¯¹è¯" if mem.task_id else "å†å²"
            # æ˜¾ç¤ºåˆ†æ•°ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼Œå¯ç§»é™¤ï¼‰
            score_info = f"[ç›¸å…³åº¦:{mem.similarity_score:.2f}]"
            lines.append(f"[{task_label}] {score_info} {mem.content}")

        return "\n".join(lines)

    def _get_vector_search(
        self,
        user_id: str,
        turns: List[Dict],
        query: Optional[str]
    ) -> List[Dict]:
        """
        å‘é‡æ£€ç´¢ç›¸å…³å†å²

        TODO: æ¥å…¥ Chroma å‘é‡æ•°æ®åº“å®ç°çœŸæ­£çš„è¯­ä¹‰æ£€ç´¢

        å½“å‰å®ç°: é™çº§ä¸ºå…³é”®è¯åŒ¹é… + æ—¶é—´è¡°å‡

        Args:
            user_id: ç”¨æˆ·ID
            turns: å†å²è½®æ¬¡åˆ—è¡¨
            query: å½“å‰æŸ¥è¯¢æ–‡æœ¬

        Returns:
            æ£€ç´¢åˆ°çš„ç›¸å…³è½®æ¬¡åˆ—è¡¨ (Top-K)
        """
        # TODO: æ¥å…¥ Chroma å®ç°å‘é‡æ£€ç´¢
        # ç¤ºä¾‹ä»£ç ï¼ˆåç»­å®ç°ï¼‰:
        # ```
        # from database.vector_store import VectorStore
        # vector_store = VectorStore()
        # results = vector_store.search(
        #     user_id=user_id,
        #     query=query,
        #     top_k=self.RETRIEVAL_TOP_K
        # )
        # return results
        # ```

        # å½“å‰é™çº§æ–¹æ¡ˆ: å…³é”®è¯åŒ¹é…
        return self._keyword_search(turns, query)

    def _keyword_search(
        self,
        turns: List[Dict],
        query: Optional[str]
    ) -> List[Dict]:
        """
        é™çº§æ–¹æ¡ˆ: å…³é”®è¯åŒ¹é…æ£€ç´¢

        è®¡ç®—å…¬å¼: score = 0.5 * relevance + 0.3 * recency
        """
        if not turns:
            return []

        # å¦‚æœæ²¡æœ‰æŸ¥è¯¢è¯ï¼Œè¿”å›æœ€è¿‘çš„å‡ è½®
        if not query:
            return turns[-self.RETRIEVAL_TOP_K:]

        query_lower = query.lower()
        query_words = [w for w in query_lower.split() if len(w) > 1]

        scored_turns = []
        for i, turn in enumerate(turns):
            # æ„å»ºè½®æ¬¡æ–‡æœ¬
            text = self._turn_to_text(turn).lower()

            # å…³é”®è¯åŒ¹é…åˆ†æ•°
            relevance_score = sum(1 for word in query_words if word in text)

            # æ–°é²œåº¦åˆ†æ•°
            recency_score = i / len(turns) if turns else 0

            # ç»¼åˆåˆ†æ•°
            combined_score = 0.5 * relevance_score + 0.3 * recency_score

            scored_turns.append({
                **turn,
                '_score': combined_score
            })

        # æŒ‰åˆ†æ•°æ’åºï¼Œå– Top-K
        scored_turns.sort(key=lambda x: x['_score'], reverse=True)
        return scored_turns[:self.RETRIEVAL_TOP_K]

    # ============ è¾…åŠ©æ–¹æ³• ============

    def _messages_to_turns(self, messages: List[ChatMessage]) -> List[Dict]:
        """
        å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºè½®æ¬¡åˆ—è¡¨

        ä¸€è½® = ä¸€æ¬¡ç”¨æˆ·æ¶ˆæ¯ + ä¸€æ¬¡AIå›å¤
        """
        turns = []
        current_turn = {'user': None, 'assistant': None, 'task_id': None}

        for msg in messages:
            if msg.is_user:
                # å¦‚æœå½“å‰è½®å·²æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼Œå…ˆä¿å­˜
                if current_turn['user'] is not None:
                    turns.append(current_turn)
                    current_turn = {'user': None, 'assistant': None, 'task_id': None}
                current_turn['user'] = msg.content
                current_turn['task_id'] = msg.task_id
            else:
                current_turn['assistant'] = msg.content
                if current_turn['task_id'] is None:
                    current_turn['task_id'] = msg.task_id
                # AIå›å¤åï¼Œä¸€è½®ç»“æŸ
                if current_turn['user'] is not None:
                    turns.append(current_turn)
                    current_turn = {'user': None, 'assistant': None, 'task_id': None}

        # å¤„ç†æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è½®æ¬¡
        if current_turn['user'] is not None:
            turns.append(current_turn)

        return turns

    def _turn_to_text(self, turn: Dict) -> str:
        """å°†è½®æ¬¡è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…ï¼‰"""
        parts = []
        if turn.get('user'):
            parts.append(turn['user'])
        if turn.get('assistant'):
            parts.append(turn['assistant'])
        return " ".join(parts)

    def _format_turns(self, turns: List[Dict]) -> str:
        """æ ¼å¼åŒ–è½®æ¬¡ä¸ºå¯¹è¯æ–‡æœ¬"""
        lines = []
        for turn in turns:
            if turn.get('user'):
                lines.append(f"ç”¨æˆ·ï¼š{turn['user']}")
            if turn.get('assistant'):
                lines.append(f"AIåŠ©æ‰‹ï¼š{turn['assistant']}")
        return "\n".join(lines)

    def _format_turns_with_source(self, turns: List[Dict]) -> str:
        """æ ¼å¼åŒ–è½®æ¬¡ï¼ˆå¸¦æ¥æºæ ‡è®°ï¼Œç”¨äºæ··åˆè®°å¿†ï¼‰"""
        lines = []
        for turn in turns:
            task_id = turn.get('task_id', '?')
            if turn.get('user'):
                lines.append(f"[ç¬¬{task_id}æ¬¡å¯¹è¯] ç”¨æˆ·ï¼š{turn['user']}")
            if turn.get('assistant'):
                lines.append(f"[ç¬¬{task_id}æ¬¡å¯¹è¯] AIåŠ©æ‰‹ï¼š{turn['assistant']}")
        return "\n".join(lines)

    def _generate_gist_summary(self, turns: List[Dict]) -> str:
        """
        ç”Ÿæˆè¦ä¹‰æ‘˜è¦ (Gist Summary)

        å°† Verbatim (å­—é¢ä¿¡æ¯) è½¬åŒ–ä¸º Gist (è¯­ä¹‰è¦ä¹‰)
        """
        if not turns:
            return ""

        # æ„å»ºå¯¹è¯æ–‡æœ¬
        conversation_text = self._format_turns(turns)

        # å¦‚æœæœ‰ LLM managerï¼Œä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        if self.llm_manager and hasattr(self.llm_manager, 'generate_summary'):
            try:
                summary = self.llm_manager.generate_summary(
                    conversation_text,
                    self.GIST_MAX_CHARS
                )
                if summary:
                    return summary
            except Exception as e:
                print(f"[MemoryEngine] LLMæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")

        # é™çº§æ–¹æ¡ˆ: æå–å…³é”®ä¿¡æ¯
        return self._extract_key_information(conversation_text)

    def _extract_key_information(self, text: str) -> str:
        """
        é™çº§æ–¹æ¡ˆ: ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯

        ç”¨äº LLM ä¸å¯ç”¨æ—¶çš„æ‘˜è¦ç”Ÿæˆ
        """
        lines = text.split('\n')

        # æå–ç”¨æˆ·å‘è¨€ä¸­çš„å…³é”®ä¿¡æ¯
        user_info = []
        for line in lines:
            if line.startswith('ç”¨æˆ·ï¼š'):
                content = line[3:].strip()
                if len(content) > 15:
                    user_info.append(content)

        # é™åˆ¶æ•°é‡
        if len(user_info) > 5:
            user_info = user_info[:3] + user_info[-2:]

        if user_info:
            summary = "ç”¨æˆ·æ›¾æåˆ°ï¼š" + "ï¼›".join(user_info[:3])
            if len(summary) > self.GIST_MAX_CHARS:
                summary = summary[:self.GIST_MAX_CHARS] + "..."
            return summary

        return ""

    # ============ ç»Ÿè®¡æ–¹æ³• ============

    def get_memory_stats(self, user_id: str) -> Dict:
        """è·å–ç”¨æˆ·çš„è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
        messages = self.db.get_user_all_messages(user_id)
        turns = self._messages_to_turns(messages)

        return {
            'total_messages': len(messages),
            'total_turns': len(turns),
            'user_messages': sum(1 for m in messages if m.is_user),
            'ai_messages': sum(1 for m in messages if not m.is_user),
        }
