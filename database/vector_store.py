"""
å‘é‡å­˜å‚¨å±‚ (Vector Store) - Numpy ç‰ˆ

ä½¿ç”¨ Numpy + SQLite å®ç° L4 æ··åˆè®°å¿†æ£€ç´¢

åŠŸèƒ½ï¼š
- DashScope Embedding API (é€šä¹‰åƒé—® text-embedding-v3)
- å‘é‡å­˜å…¥ SQLite chat_messages.embedding å­—æ®µ
- Numpy ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
- åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢ï¼ˆåŸºäºCHI'24 Hou et al.ï¼‰ï¼š
  å…¬å¼: p_n(t) = [1 - exp(-rÂ·e^{-t/g_n})] / (1 - e^{-1})
  å›ºåŒ–æ›´æ–°: g_n = g_{n-1} + S(t), S(t) = (1-e^{-t})/(1+e^{-t})
"""

import json
import math
import requests
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field

from config import Config


@dataclass
class MemoryItem:
    """æ£€ç´¢ç»“æœæ¡ç›®ï¼ˆL4 åŠ¨æ€é—å¿˜æ›²çº¿å¢å¼ºç‰ˆï¼‰"""
    message_id: str
    user_id: str
    task_id: int
    content: str
    timestamp: datetime
    is_user: bool
    importance_score: float
    similarity_score: float = 0.0
    recency_score: float = 0.0
    final_score: float = 0.0
    # åŠ¨æ€é—å¿˜æ›²çº¿å­—æ®µ
    consolidation_g: float = 1.0       # å›ºåŒ–ç³»æ•° g_n
    recall_count: int = 0              # å¬å›æ¬¡æ•° n
    recall_probability: float = 0.0    # å¬å›æ¦‚ç‡ p(t)
    days_since_last_recall: float = 0.0  # è·ä¸Šæ¬¡å¬å›å¤©æ•°
    # æƒ…æ„Ÿæ˜¾è‘—æ€§å­—æ®µï¼ˆCHI'24 å¢å¼ºï¼‰
    emotional_salience: float = 0.0    # æƒ…æ„Ÿæ˜¾è‘—æ€§åˆ†æ•°

    def to_dict(self) -> Dict:
        return {
            'message_id': self.message_id,
            'user_id': self.user_id,
            'task_id': self.task_id,
            'content': self.content,
            'timestamp': self.timestamp.isoformat() if self.timestamp else None,
            'is_user': self.is_user,
            'importance_score': round(self.importance_score, 3),
            'similarity_score': round(self.similarity_score, 3),
            'recency_score': round(self.recency_score, 3),
            'final_score': round(self.final_score, 3),
            # åŠ¨æ€é—å¿˜æ›²çº¿å­—æ®µ
            'consolidation_g': round(self.consolidation_g, 3),
            'recall_count': self.recall_count,
            'recall_probability': round(self.recall_probability, 3),
            'days_since_last_recall': round(self.days_since_last_recall, 2),
            # æƒ…æ„Ÿæ˜¾è‘—æ€§å­—æ®µ
            'emotional_salience': round(self.emotional_salience, 3),
        }


class DynamicMemoryRecall:
    """
    åŠ¨æ€è®°å¿†å¬å›æ¨¡å‹ï¼ˆåŸºäºCHI'24 Hou et al.ï¼‰

    æ ¸å¿ƒå…¬å¼ï¼š
    - å¬å›æ¦‚ç‡: p_n(t) = [1 - exp(-r Â· e^{-t/g_n})] / (1 - e^{-1})
    - å›ºåŒ–æ›´æ–°: g_n = g_{n-1} + S(t), S(t) = (1-e^{-t})/(1+e^{-t})

    å…¶ä¸­:
    - r = è¯­ä¹‰ç›¸ä¼¼åº¦ (cosine similarity, 0-1)
    - t = è·ä¸Šæ¬¡å¬å›çš„æ—¶é—´é—´éš”ï¼ˆå¤©ï¼‰
    - g_n = ç´¯ç§¯å›ºåŒ–å¼ºåº¦ï¼ˆå¬å›æ¬¡æ•°è¶Šå¤šï¼Œgè¶Šå¤§ï¼Œè¡°å‡è¶Šæ…¢ï¼‰
    """

    def __init__(
        self,
        initial_g: float = 1.0,
        recall_threshold: float = 0.86,
        time_unit: str = 'days'
    ):
        """
        åˆå§‹åŒ–åŠ¨æ€è®°å¿†å¬å›æ¨¡å‹

        Args:
            initial_g: åˆå§‹å›ºåŒ–ç³»æ•° g_0 (é»˜è®¤ 1.0)
            recall_threshold: å¬å›æ¦‚ç‡é˜ˆå€¼ k (é»˜è®¤ 0.86ï¼ŒCHIè®ºæ–‡å»ºè®®å€¼)
            time_unit: æ—¶é—´å•ä½ ('days', 'hours', 'seconds')
        """
        self.initial_g = initial_g
        self.recall_threshold = recall_threshold
        self.time_unit = time_unit

    def calculate_recall_probability(
        self,
        relevance: float,
        elapsed_time: float,
        consolidation_g: float = None
    ) -> float:
        """
        è®¡ç®—å¬å›æ¦‚ç‡ï¼ˆCHIè®ºæ–‡å…¬å¼8ï¼‰

        p_n(t) = [1 - exp(-r Â· e^{-t/g_n})] / (1 - e^{-1})

        Args:
            relevance: r - è¯­ä¹‰ç›¸ä¼¼åº¦ (0-1)
            elapsed_time: t - è·ä¸Šæ¬¡å¬å›çš„æ—¶é—´ï¼ˆå•ä½ç”±time_unitå†³å®šï¼‰
            consolidation_g: g_n - å½“å‰å›ºåŒ–ç³»æ•°

        Returns:
            å¬å›æ¦‚ç‡ (0-1)
        """
        if consolidation_g is None or consolidation_g <= 0:
            consolidation_g = self.initial_g

        # é¿å…é™¤é›¶
        if consolidation_g == 0:
            consolidation_g = 0.001

        # æŒ‡æ•°è¡°å‡é¡¹: e^{-t/g_n}
        decay_term = math.exp(-elapsed_time / consolidation_g)

        # å¬å›æ¦‚ç‡åˆ†å­: 1 - exp(-r Â· decay_term)
        numerator = 1 - math.exp(-relevance * decay_term)

        # å½’ä¸€åŒ–åˆ†æ¯: 1 - e^{-1} â‰ˆ 0.632
        denominator = 1 - math.exp(-1)

        probability = numerator / denominator

        # ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
        return max(0.0, min(1.0, probability))

    def update_consolidation(
        self,
        current_g: float,
        recall_interval: float
    ) -> float:
        """
        æ›´æ–°å›ºåŒ–ç³»æ•°ï¼ˆCHIè®ºæ–‡å…¬å¼9ï¼‰

        g_n = g_{n-1} + S(t)
        S(t) = (1 - e^{-t}) / (1 + e^{-t})  (ä¿®æ­£sigmoid)

        å¬å›é—´éš”è¶Šé•¿ï¼ŒS(t)è¶Šå¤§ï¼Œå›ºåŒ–å¼ºåº¦å¢åŠ è¶Šå¤š
        è¿™æ¨¡æ‹Ÿäº†"é—´éš”æ•ˆåº”"ï¼šé—´éš”è¾ƒé•¿çš„é‡å¤æ¯”é—´éš”è¾ƒçŸ­çš„é‡å¤æ›´æœ‰æ•ˆ

        Args:
            current_g: å½“å‰å›ºåŒ–ç³»æ•° g_{n-1}
            recall_interval: è·ä¸Šæ¬¡å¬å›çš„æ—¶é—´é—´éš”

        Returns:
            æ›´æ–°åçš„å›ºåŒ–ç³»æ•° g_n
        """
        t = max(0.001, recall_interval)  # é¿å… t=0

        # ä¿®æ­£sigmoid: S(t) = (1 - e^{-t}) / (1 + e^{-t})
        # å½“ t â†’ 0: S(t) â†’ 0
        # å½“ t â†’ âˆ: S(t) â†’ 1
        s_t = (1 - math.exp(-t)) / (1 + math.exp(-t))

        return current_g + s_t

    def should_recall(self, probability: float) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å¬å›

        Args:
            probability: å¬å›æ¦‚ç‡

        Returns:
            æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        """
        return probability >= self.recall_threshold

    def calculate_elapsed_days(
        self,
        last_recall_at: datetime,
        current_time: datetime = None
    ) -> float:
        """
        è®¡ç®—è·ä¸Šæ¬¡å¬å›çš„å¤©æ•°

        Args:
            last_recall_at: ä¸Šæ¬¡å¬å›æ—¶é—´
            current_time: å½“å‰æ—¶é—´ï¼ˆé»˜è®¤ nowï¼‰

        Returns:
            å¤©æ•°ï¼ˆæµ®ç‚¹æ•°ï¼‰
        """
        if current_time is None:
            current_time = datetime.utcnow()

        if last_recall_at is None:
            # å¦‚æœä»æœªè¢«å¬å›ï¼Œä½¿ç”¨æ¶ˆæ¯åˆ›å»ºæ—¶é—´
            return 1.0  # é»˜è®¤1å¤©

        delta = current_time - last_recall_at

        if self.time_unit == 'days':
            return delta.total_seconds() / 86400.0
        elif self.time_unit == 'hours':
            return delta.total_seconds() / 3600.0
        else:
            return delta.total_seconds()


class DashScopeEmbedding:
    """é€šä¹‰åƒé—® text-embedding-v3 API"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or Config.EXPERIMENT_CONFIG.get('qwen_api_key')
        self.base_url = "https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding"
        self.model = "text-embedding-v3"
        self.dimension = 1024

    def embed_texts(self, texts: List[str]) -> List[Optional[List[float]]]:
        """æ‰¹é‡ç”Ÿæˆå‘é‡"""
        if not texts:
            return []

        results = []
        batch_size = 10  # API é™åˆ¶: text-embedding-v3 æœ€å¤§ 10 æ¡

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_results = self._call_api(batch)
            results.extend(batch_results)

        return results

    def embed_single(self, text: str) -> Optional[List[float]]:
        """ç”Ÿæˆå•ä¸ªå‘é‡"""
        if not text or not text.strip():
            return None
        results = self._call_api([text])
        return results[0] if results else None

    def _call_api(self, texts: List[str], verbose: bool = False) -> List[Optional[List[float]]]:
        """è°ƒç”¨ API"""
        try:
            if verbose:
                print(f"[Embedding] è°ƒç”¨ API:")
                print(f"    URL: {self.base_url}")
                print(f"    Model: {self.model}")
                print(f"    API Key: {self.api_key[:10]}...{self.api_key[-4:] if len(self.api_key) > 14 else ''}")
                print(f"    Texts: {len(texts)} æ¡")

            response = requests.post(
                self.base_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "input": {"texts": texts},
                    "parameters": {"text_type": "document", "dimension": self.dimension}
                },
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                if 'output' in data and 'embeddings' in data['output']:
                    sorted_emb = sorted(data['output']['embeddings'], key=lambda x: x['text_index'])
                    return [item['embedding'] for item in sorted_emb]

            # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
            print(f"[Embedding] API é”™è¯¯: HTTP {response.status_code}")
            try:
                error_data = response.json()
                print(f"[Embedding] é”™è¯¯è¯¦æƒ…:")
                print(f"    code: {error_data.get('code', 'N/A')}")
                print(f"    message: {error_data.get('message', 'N/A')}")
                print(f"    request_id: {error_data.get('request_id', 'N/A')}")
            except:
                print(f"[Embedding] å“åº”å†…å®¹: {response.text[:500]}")

            return [None] * len(texts)

        except Exception as e:
            print(f"[Embedding] è¯·æ±‚å¤±è´¥: {e}")
            return [None] * len(texts)

    def test_single(self, text: str = "è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯") -> bool:
        """æµ‹è¯•å•æ¡æ¶ˆæ¯å‘é‡åŒ–"""
        print("\n" + "=" * 50)
        print("Embedding API å•æ¡æµ‹è¯•")
        print("=" * 50)
        print(f"æµ‹è¯•æ–‡æœ¬: {text}")
        print()

        result = self._call_api([text], verbose=True)

        if result and result[0]:
            print(f"\n[OK] æˆåŠŸ! å‘é‡ç»´åº¦: {len(result[0])}")
            print(f"     å‘é‡å‰5ä¸ªå€¼: {result[0][:5]}")
            return True
        else:
            print(f"\n[FAIL] å¤±è´¥!")
            return False


def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """
    è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦

    Returns:
        ç›¸ä¼¼åº¦ 0-1 (å·²å½’ä¸€åŒ–)
    """
    if not vec1 or not vec2:
        return 0.0

    a = np.array(vec1, dtype=np.float32)
    b = np.array(vec2, dtype=np.float32)

    dot = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)

    if norm_a == 0 or norm_b == 0:
        return 0.0

    # ä½™å¼¦ç›¸ä¼¼åº¦ [-1, 1] â†’ å½’ä¸€åŒ–åˆ° [0, 1]
    sim = dot / (norm_a * norm_b)
    return float((sim + 1) / 2)


class VectorStore:
    """
    å‘é‡å­˜å‚¨ç®¡ç†å™¨ï¼ˆL4 åŠ¨æ€é—å¿˜æ›²çº¿å¢å¼ºç‰ˆï¼‰

    æ£€ç´¢ç­–ç•¥:
    1. æ—§ç‰ˆé™æ€åŠ æƒ: Score = Î±Â·Recency + Î²Â·Similarity + Î³Â·Importance
    2. æ–°ç‰ˆåŠ¨æ€é—å¿˜æ›²çº¿ï¼ˆCHI'24ï¼‰: p_n(t) = [1-exp(-rÂ·e^{-t/g_n})]/(1-e^{-1})

    ä½¿ç”¨åŠ¨æ€é—å¿˜æ›²çº¿æ—¶:
    - æ¦‚ç‡é˜ˆå€¼è§¦å‘å¬å›ï¼ˆè€Œéç®€å•Top-Kï¼‰
    - å¬å›åæ›´æ–°å›ºåŒ–ç³»æ•°ï¼ˆè¶Šå›å¿†è¶Šç‰¢å›ºï¼‰
    """

    # ä» config.py è¯»å–æƒé‡
    WEIGHTS = Config.MEMORY_OPERATIONS.get('hybrid_memory', {
        'alpha': 0.3,
        'beta': 0.5,
        'gamma': 0.2
    })

    # ä» config.py è¯»å–é—å¿˜æ›²çº¿é…ç½®
    FORGETTING_CURVE_CONFIG = Config.EXPERIMENT_CONFIG.get('memory_config', {}).get(
        'hybrid_memory', {}
    ).get('forgetting_curve', {
        'enabled': True,
        'initial_g': 1.0,
        'recall_threshold': 0.86,
        'time_unit': 'days',
        'update_on_recall': True
    })

    def __init__(self, db_manager=None):
        """
        åˆå§‹åŒ–

        Args:
            db_manager: DBManager å®ä¾‹ï¼ˆç”¨äºæ•°æ®åº“æ“ä½œï¼‰
        """
        self.db = db_manager
        self.embedding_fn = DashScopeEmbedding()

        # åˆå§‹åŒ–åŠ¨æ€è®°å¿†å¬å›æ¨¡å‹
        self.recall_model = DynamicMemoryRecall(
            initial_g=self.FORGETTING_CURVE_CONFIG.get('initial_g', 1.0),
            recall_threshold=self.FORGETTING_CURVE_CONFIG.get('recall_threshold', 0.86),
            time_unit=self.FORGETTING_CURVE_CONFIG.get('time_unit', 'days')
        )

    def set_db_manager(self, db_manager):
        """è®¾ç½®æ•°æ®åº“ç®¡ç†å™¨"""
        self.db = db_manager

    def generate_embedding(self, text: str) -> Optional[List[float]]:
        """ç”Ÿæˆå•æ¡æ–‡æœ¬çš„å‘é‡"""
        return self.embedding_fn.embed_single(text)

    def generate_embeddings_batch(self, texts: List[str]) -> List[Optional[List[float]]]:
        """æ‰¹é‡ç”Ÿæˆå‘é‡"""
        return self.embedding_fn.embed_texts(texts)

    def search_weighted(
        self,
        user_id: str,
        query: str,
        exclude_task_id: int = None,
        top_k: int = 3,
        alpha: float = None,
        beta: float = None,
        gamma: float = None
    ) -> List[MemoryItem]:
        """
        åŠ æƒå‘é‡æ£€ç´¢

        Score = Î±Â·Recency + Î²Â·Similarity + Î³Â·Importance

        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢æ–‡æœ¬
            exclude_task_id: æ’é™¤çš„ä»»åŠ¡IDï¼ˆå½“å‰ä»»åŠ¡ï¼‰
            top_k: è¿”å›æ•°é‡
            alpha: æ–°é²œåº¦æƒé‡ (é»˜è®¤ 0.3)
            beta: ç›¸ä¼¼åº¦æƒé‡ (é»˜è®¤ 0.5)
            gamma: é‡è¦æ€§æƒé‡ (é»˜è®¤ 0.2)

        Returns:
            æ’åºåçš„è®°å¿†åˆ—è¡¨
        """
        if not self.db:
            print("[VectorStore] æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        # ä½¿ç”¨é…ç½®æƒé‡
        alpha = alpha if alpha is not None else self.WEIGHTS['alpha']
        beta = beta if beta is not None else self.WEIGHTS['beta']
        gamma = gamma if gamma is not None else self.WEIGHTS['gamma']

        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_fn.embed_single(query)
        if not query_embedding:
            print("[VectorStore] æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥")
            return []

        # 2. è·å–ç”¨æˆ·æ‰€æœ‰æœ‰å‘é‡çš„å†å²æ¶ˆæ¯
        messages = self._get_user_messages_with_embedding(user_id, exclude_task_id)
        if not messages:
            return []

        # 3. è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆç”¨äºæ–°é²œåº¦å½’ä¸€åŒ–ï¼‰
        timestamps = [m['timestamp'] for m in messages]
        min_ts = min(timestamps)
        max_ts = max(timestamps)
        time_range = (max_ts - min_ts).total_seconds() or 1

        # 4. è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„åŠ æƒåˆ†æ•°
        results = []
        for msg in messages:
            # Î²: ç›¸ä¼¼åº¦
            similarity = cosine_similarity(query_embedding, msg['embedding'])

            # Î±: æ–°é²œåº¦ (0=æœ€æ—§, 1=æœ€æ–°)
            recency = (msg['timestamp'] - min_ts).total_seconds() / time_range

            # Î³: é‡è¦æ€§
            importance = msg.get('importance_score', 0.5)

            # åŠ æƒå…¬å¼
            final_score = alpha * recency + beta * similarity + gamma * importance

            results.append(MemoryItem(
                message_id=msg['message_id'],
                user_id=msg['user_id'],
                task_id=msg['task_id'],
                content=msg['content'],
                timestamp=msg['timestamp'],
                is_user=msg['is_user'],
                importance_score=importance,
                similarity_score=similarity,
                recency_score=recency,
                final_score=final_score
            ))

        # 5. æŒ‰åˆ†æ•°æ’åºï¼Œå– Top-K
        results.sort(key=lambda x: x.final_score, reverse=True)
        return results[:top_k]

    def search_with_forgetting_curve(
        self,
        user_id: str,
        query: str,
        exclude_task_id: int = None,
        top_k: int = 5,
        update_on_recall: bool = True
    ) -> List[MemoryItem]:
        """
        åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢ï¼ˆCHI'24 Hou et al.ï¼‰

        æ ¸å¿ƒå…¬å¼:
        - å¬å›æ¦‚ç‡: p_n(t) = [1 - exp(-r Â· e^{-t/g_n})] / (1 - e^{-1})
        - å›ºåŒ–æ›´æ–°: g_n = g_{n-1} + S(t)

        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢æ–‡æœ¬
            exclude_task_id: æ’é™¤çš„ä»»åŠ¡IDï¼ˆå½“å‰ä»»åŠ¡ï¼‰
            top_k: æœ€å¤§è¿”å›æ•°é‡ï¼ˆåœ¨é˜ˆå€¼ç­›é€‰åï¼‰
            update_on_recall: æ˜¯å¦åœ¨å¬å›åæ›´æ–°å›ºåŒ–ç³»æ•°

        Returns:
            ç¬¦åˆå¬å›é˜ˆå€¼çš„è®°å¿†åˆ—è¡¨ï¼ˆæŒ‰å¬å›æ¦‚ç‡æ’åºï¼‰
        """
        if not self.db:
            print("[VectorStore] æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_fn.embed_single(query)
        if not query_embedding:
            print("[VectorStore] æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥ï¼Œé™çº§ä¸ºé™æ€æ£€ç´¢")
            return self.search_weighted(user_id, query, exclude_task_id, top_k)

        # 2. è·å–ç”¨æˆ·æ‰€æœ‰æœ‰å‘é‡çš„å†å²æ¶ˆæ¯ï¼ˆå«åŠ¨æ€å­—æ®µï¼‰
        messages = self._get_user_messages_with_dynamic_fields(user_id, exclude_task_id)
        if not messages:
            return []

        current_time = datetime.utcnow()
        recalled_memories = []
        recall_model = self.recall_model

        # 3. è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„å¬å›æ¦‚ç‡ï¼ˆèåˆæƒ…æ„Ÿæ˜¾è‘—æ€§ï¼‰
        for msg in messages:
            # è¯­ä¹‰ç›¸ä¼¼åº¦ r
            similarity = cosine_similarity(query_embedding, msg['embedding'])

            # è·ä¸Šæ¬¡å¬å›çš„æ—¶é—´ tï¼ˆå¤©ï¼‰
            last_recall = msg.get('last_recall_at') or msg['timestamp']
            elapsed_days = recall_model.calculate_elapsed_days(last_recall, current_time)

            # å›ºåŒ–ç³»æ•° g_n
            consolidation_g = msg.get('consolidation_g', 1.0)

            # ğŸ”´ æƒ…æ„Ÿæ˜¾è‘—æ€§ (CHI'24 å¢å¼º)
            emotional_salience = msg.get('emotional_salience', 0.0)

            # è®¡ç®—åŸºç¡€å¬å›æ¦‚ç‡
            base_recall_prob = recall_model.calculate_recall_probability(
                relevance=similarity,
                elapsed_time=elapsed_days,
                consolidation_g=consolidation_g
            )

            # ğŸ”´ æƒ…æ„Ÿæ˜¾è‘—æ€§åŠ æˆï¼šé«˜æƒ…æ„Ÿæ˜¾è‘—æ€§çš„è®°å¿†æ›´å®¹æ˜“è¢«å¬å›
            # å…¬å¼: final_prob = base_prob + emotional_bonus
            # emotional_bonus = emotional_salience * 0.1 (æœ€å¤šæå‡0.1)
            emotional_bonus = emotional_salience * 0.1
            recall_prob = min(1.0, base_recall_prob + emotional_bonus)

            # åˆ›å»º MemoryItem
            memory = MemoryItem(
                message_id=msg['message_id'],
                user_id=msg['user_id'],
                task_id=msg['task_id'],
                content=msg['content'],
                timestamp=msg['timestamp'],
                is_user=msg['is_user'],
                importance_score=msg.get('importance_score', 0.5),
                similarity_score=similarity,
                consolidation_g=consolidation_g,
                recall_count=msg.get('recall_count', 0),
                recall_probability=recall_prob,
                days_since_last_recall=elapsed_days,
                final_score=recall_prob,  # ä½¿ç”¨å¬å›æ¦‚ç‡ä½œä¸ºæœ€ç»ˆåˆ†æ•°
                emotional_salience=emotional_salience  # ğŸ”´ æƒ…æ„Ÿæ˜¾è‘—æ€§
            )

            # 4. é˜ˆå€¼ç­›é€‰ï¼šåªæœ‰è¶…è¿‡é˜ˆå€¼çš„æ‰è¢«å¬å›
            if recall_model.should_recall(recall_prob):
                recalled_memories.append(memory)

                # 5. æ›´æ–°å›ºåŒ–ç³»æ•°ï¼ˆè¢«å¬å›åå˜å¾—æ›´éš¾é—å¿˜ï¼‰
                if update_on_recall and self.FORGETTING_CURVE_CONFIG.get('update_on_recall', True):
                    new_g = recall_model.update_consolidation(consolidation_g, elapsed_days)
                    new_recall_count = msg.get('recall_count', 0) + 1

                    self._update_memory_dynamic_fields(
                        msg['message_id'],
                        consolidation_g=new_g,
                        recall_count=new_recall_count,
                        last_recall_at=current_time
                    )

        # 6. æŒ‰å¬å›æ¦‚ç‡æ’åºï¼Œå– Top-K
        recalled_memories.sort(key=lambda x: x.recall_probability, reverse=True)

        # æ—¥å¿—è¾“å‡º
        print(f"[VectorStore] åŠ¨æ€é—å¿˜æ›²çº¿æ£€ç´¢: "
              f"å€™é€‰={len(messages)}, è¶…é˜ˆå€¼={len(recalled_memories)}, "
              f"é˜ˆå€¼={recall_model.recall_threshold}")

        return recalled_memories[:top_k]

    def _get_user_messages_with_dynamic_fields(
        self,
        user_id: str,
        exclude_task_id: int = None
    ) -> List[Dict]:
        """
        è·å–ç”¨æˆ·æ‰€æœ‰æœ‰å‘é‡çš„æ¶ˆæ¯ï¼ˆå«åŠ¨æ€é—å¿˜æ›²çº¿å­—æ®µï¼‰

        Returns:
            æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«: embedding, consolidation_g, recall_count, last_recall_at
        """
        from database import ChatMessage

        try:
            query = self.db.session.query(ChatMessage).filter(
                ChatMessage.user_id == user_id,
                ChatMessage.embedding.isnot(None)
            )

            if exclude_task_id is not None:
                query = query.filter(ChatMessage.task_id != exclude_task_id)

            messages = query.all()

            result = []
            for msg in messages:
                try:
                    embedding = json.loads(msg.embedding) if msg.embedding else None
                except:
                    embedding = None

                if embedding:
                    result.append({
                        'message_id': msg.message_id,
                        'user_id': msg.user_id,
                        'task_id': msg.task_id,
                        'content': msg.content,
                        'timestamp': msg.timestamp,
                        'is_user': msg.is_user,
                        'importance_score': msg.importance_score or 0.5,
                        'embedding': embedding,
                        # åŠ¨æ€é—å¿˜æ›²çº¿å­—æ®µ
                        'consolidation_g': getattr(msg, 'consolidation_g', None) or 1.0,
                        'recall_count': getattr(msg, 'recall_count', None) or 0,
                        'last_recall_at': getattr(msg, 'last_recall_at', None),
                        'emotional_salience': getattr(msg, 'emotional_salience', None) or 0.0
                    })

            return result

        except Exception as e:
            print(f"[VectorStore] æŸ¥è¯¢å¤±è´¥: {e}")
            return []

    def _update_memory_dynamic_fields(
        self,
        message_id: str,
        consolidation_g: float = None,
        recall_count: int = None,
        last_recall_at: datetime = None
    ) -> bool:
        """
        æ›´æ–°æ¶ˆæ¯çš„åŠ¨æ€é—å¿˜æ›²çº¿å­—æ®µ

        Args:
            message_id: æ¶ˆæ¯ID
            consolidation_g: æ–°çš„å›ºåŒ–ç³»æ•°
            recall_count: æ–°çš„å¬å›æ¬¡æ•°
            last_recall_at: æ–°çš„ä¸Šæ¬¡å¬å›æ—¶é—´

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        from database import ChatMessage

        try:
            msg = self.db.session.query(ChatMessage).filter(
                ChatMessage.message_id == message_id
            ).first()

            if msg:
                if consolidation_g is not None:
                    msg.consolidation_g = consolidation_g
                if recall_count is not None:
                    msg.recall_count = recall_count
                if last_recall_at is not None:
                    msg.last_recall_at = last_recall_at

                self.db.session.commit()
                return True

            return False

        except Exception as e:
            print(f"[VectorStore] æ›´æ–°åŠ¨æ€å­—æ®µå¤±è´¥: {e}")
            self.db.session.rollback()
            return False

    def _get_user_messages_with_embedding(
        self,
        user_id: str,
        exclude_task_id: int = None
    ) -> List[Dict]:
        """
        è·å–ç”¨æˆ·æ‰€æœ‰æœ‰å‘é‡çš„æ¶ˆæ¯

        Args:
            user_id: ç”¨æˆ·ID
            exclude_task_id: æ’é™¤çš„ä»»åŠ¡ID

        Returns:
            æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«è§£æåçš„å‘é‡ï¼‰
        """
        from database import ChatMessage

        try:
            query = self.db.session.query(ChatMessage).filter(
                ChatMessage.user_id == user_id,
                ChatMessage.embedding.isnot(None)
            )

            if exclude_task_id is not None:
                query = query.filter(ChatMessage.task_id != exclude_task_id)

            messages = query.all()

            result = []
            for msg in messages:
                # è§£æ JSON æ ¼å¼çš„å‘é‡
                try:
                    embedding = json.loads(msg.embedding) if msg.embedding else None
                except:
                    embedding = None

                if embedding:
                    result.append({
                        'message_id': msg.message_id,
                        'user_id': msg.user_id,
                        'task_id': msg.task_id,
                        'content': msg.content,
                        'timestamp': msg.timestamp,
                        'is_user': msg.is_user,
                        'importance_score': msg.importance_score or 0.5,
                        'embedding': embedding
                    })

            return result

        except Exception as e:
            print(f"[VectorStore] æŸ¥è¯¢å¤±è´¥: {e}")
            return []

    def update_message_embedding(
        self,
        message_id: str,
        embedding: List[float],
        importance_score: float = None
    ) -> bool:
        """
        æ›´æ–°æ¶ˆæ¯çš„å‘é‡å’Œé‡è¦æ€§åˆ†æ•°

        Args:
            message_id: æ¶ˆæ¯ID
            embedding: å‘é‡
            importance_score: é‡è¦æ€§åˆ†æ•°

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        from database import ChatMessage

        try:
            msg = self.db.session.query(ChatMessage).filter(
                ChatMessage.message_id == message_id
            ).first()

            if msg:
                msg.embedding = json.dumps(embedding)
                if importance_score is not None:
                    msg.importance_score = importance_score
                self.db.session.commit()
                return True

            return False

        except Exception as e:
            print(f"[VectorStore] æ›´æ–°å¤±è´¥: {e}")
            self.db.session.rollback()
            return False

    def get_stats(self, user_id: str = None) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        from database import ChatMessage

        try:
            query = self.db.session.query(ChatMessage)

            if user_id:
                query = query.filter(ChatMessage.user_id == user_id)

            total = query.count()
            with_embedding = query.filter(ChatMessage.embedding.isnot(None)).count()

            return {
                "total_messages": total,
                "with_embedding": with_embedding,
                "coverage": f"{with_embedding/total*100:.1f}%" if total > 0 else "0%"
            }

        except Exception as e:
            return {"error": str(e)}


# å…¨å±€å•ä¾‹
_vector_store: Optional[VectorStore] = None


def get_vector_store(db_manager=None) -> VectorStore:
    """è·å–å‘é‡å­˜å‚¨å•ä¾‹"""
    global _vector_store
    if _vector_store is None:
        _vector_store = VectorStore(db_manager)
    elif db_manager and _vector_store.db is None:
        _vector_store.set_db_manager(db_manager)
    return _vector_store
